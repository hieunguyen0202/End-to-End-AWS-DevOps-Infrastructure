# üìò [AJ3] DevOps Project Documentation

## I. Project Overview

- Project Name: End to End AWS DevOps Infrastructure

- Objective: Automate the build, deployment, and infrastructure provisioning of a Java-based 3-tier web application using CI/CD pipelines and Infrastructure as Code (IaC).

- Key values:
    - Built modular Terraform infrastructure for DEV/UAT/DR, enabling version-controlled, repeatable deployments. Optimized provisioning, reduced manual effort, improved consistency, and ensured high availability across AZs with autoscaling, NAT, ECS, and ALBs.
    - Implemented CI/CD pipeline via GitHub Actions, deploying Java microservices to ECS Fargate with JFrog Artifactory and version tagging, enhancing deployment speed, ensuring release traceability, minimizing human error, and improving delivery consistency across environments.
    - Enhanced infrastructure security by enforcing IAM and security groups via Terraform, minimizing exposure through strict private/public segmentation, detecting code and dependency vulnerabilities with SonarQube and JFrog Xray to reduce attack surface and ensure compliance.
    - Enabled high availability and disaster recovery by configuring multi-AZ RDS (MySQL) with automated backups, cross-region snapshot replication, and structured DR playbooks to meet SLA uptime target of 99.95%.
    - Enforced centralized monitoring and alerting using AWS CloudWatch Alarms, AWS CloudTrail, and VPC Flow Logs to track resource health, container behavior, and suspicious activity‚Äîenhancing observability and response readiness across all environments.

- Tech Stack: GitHub Actions, Terraform, Docker, ECS, ECR, SonarCloud, JFrog, RDS (MySQL), Amazon MQ, ElastiCache (Memcached), CloudWatch, CloudFront, ALB, Nginx, Tomcat, Maven.


- AWS Landing Zone

![alt text](EndToEnd-AWSLandingZone.drawio-1.png)

- Architecture Diagram: (AWS-JAVA-3TIER)

![alt text](<End-to-End.drawio (1).svg>)

## II. High-Level Architecture

### üåê AWS Account Structuring Overview:

```
AWS Organizations
‚îÇ
‚îú‚îÄ‚îÄ Root Account
‚îÇ
‚îú‚îÄ‚îÄ OU: Sandbox / Dev
‚îÇ   ‚îî‚îÄ‚îÄ AWS Account: dev-account
‚îÇ
‚îú‚îÄ‚îÄ OU: Non-Prod
‚îÇ   ‚îî‚îÄ‚îÄ AWS Account: uat-account

```

- Dev Account: d√πng b·ªüi developers, √≠t h·∫°n ch·∫ø (nh∆∞ng v·∫´n theo IAM, guardrails)
- UAT Account: ki·ªÉm th·ª≠ tr∆∞·ªõc khi l√™n Prod, t√°ch bi·ªát ho√†n to√†n kh·ªèi Dev


```
terraform-aws/
‚îú‚îÄ‚îÄ envs/
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend.tf (S3 bucket: dev-tf-state)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ provider.tf (assume role to dev AWS account)
‚îÇ   ‚îî‚îÄ‚îÄ uat/
‚îÇ       ‚îú‚îÄ‚îÄ main.tf
‚îÇ       ‚îú‚îÄ‚îÄ variables.tf
‚îÇ       ‚îú‚îÄ‚îÄ backend.tf (bucket: uat-tf-state)
‚îÇ       ‚îî‚îÄ‚îÄ provider.tf (assume role to uat AWS account)
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ network-vpc/
‚îÇ   ‚îî‚îÄ‚îÄ ecs/
```

### üåê Backend State per environment:

envs/dev/backend.tf:

```
terraform {
  backend "s3" {
    bucket         = "dev-tf-state"
    key            = "vpc/main.tfstate"
    region         = "ap-southeast-1"
    dynamodb_table = "dev-tf-lock"
    encrypt        = true
  }
}

```

envs/uat/backend.tf:

```
terraform {
  backend "s3" {
    bucket         = "uat-tf-state"
    key            = "vpc/main.tfstate"
    region         = "ap-southeast-1"
    dynamodb_table = "uat-tf-lock"
    encrypt        = true
  }
}

```

### üîÅ Full Terraform Workflow Step-by-Step

- Developer t·∫°o feature branch feature/add-s3-bucket
- Vi·∫øt code trong module v√† folder envs/dev
- Push l√™n GitHub -> m·ªü Pull Request v√†o branch dev
- CI Pipeline ch·∫°y:
  - terraform init -backend-config=... (dev)
  - terraform plan
  - Upload terraform plan output v√†o PR comment (CI/CD)

    ```
    - name: Terraform Plan
      id: plan
      run: |
        terraform plan -input=false -no-color > tfplan.txt

    - name: Upload Plan to PR Comment
      uses: juliangruber/terraform-plan-commenter@v1.2.0
      with:
        plan: tfplan.txt
        github_token: ${{ secrets.GITHUB_TOKEN }}
    ```

- Reviewer approve ‚Üí Merge v√†o branch dev
- CI c·ªßa branch dev ch·∫°y terraform apply T·ª∞ ƒê·ªòNG l√™n m√¥i tr∆∞·ªùng DEV
- Khi DEV stable ‚Üí t·∫°o PR t·ª´ dev ‚Üí main
- CI ch·∫°y plan cho m√¥i tr∆∞·ªùng UAT (envs/uat)
- Approve & merge ‚Üí CI branch main ch·∫°y terraform apply l√™n UAT





### üîÅ Deployment Strategy

#T·∫°o m·ªôt tag v√† push l√™n github repository c·ªßa b·∫°n. Vd: v1.0.0
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin v1.0.0
#Ch·∫°y job [BlueGreen-Job1-Build] v·ªõi tham s·ªë version = v1.0.0
#Ki·ªÉm tra job ch·∫°y th√†nh c√¥ng v√† image ƒë√£ ƒë∆∞·ª£c push l√™n ECR repository.

#=========Step 3: S·ª≠ d·ª•ng Terraform ƒë·ªÉ deploy ra stack
cd terraform/envs/dev/
#Ch·ªânh s·ª≠a file sau: senvs/dev/terraform.tfvars
#  - Ch·ªânh s·ª≠a th√†nh url ECR repository c·ªßa b·∫°n v√≠ d·ª•:
     430950558682.dkr.ecr.ap-southeast-1.amazonaws.com/nodejs-random-color:v1.0.0

#Ch·∫°y c√°c l·ªánh sau:

```
terraform init
terraform plan --var-file "terraform.tfvars"
terraform apply --var-file "terraform.tfvars"

```

#Ki·ªÉm tra resource ƒë∆∞·ª£c t·∫°o ra th√†nh c√¥ng tr√™n AWS.
#L∆∞u √Ω, terraform stack s·∫Ω t·∫°o ra 2 c·ª•m ECS Cluster v√† 2 Target Group, 1 ALB. Tr√™n ALB c√≥ 2 listener n√™n c·∫ßn ki·ªÉm tra c·∫£ hai.

#Truy c·∫≠p ALB b·∫±ng port 80, ki·ªÉm tra trang index hi·ªÉn th·ªã ƒë√∫ng version v1.0.0 (2 m√†u kh√°c nhau).
#Truy c·∫≠p ALB b·∫±ng port 81, ki·ªÉm tra trang index hi·ªÉn th·ªã ƒë√∫ng version v1.0.0 (2 m√†u kh√°c nhau).

#==========Step 4: T·∫°o Job Deploy:

#T·∫°o m·ªôt Job Jenkins m·ªõi, ƒë·∫∑t t√™n l√† BlueGreen-Job2-Deploy-ECS.

#Nh·∫≠p tham s·ªë cho job: VERSION (String), default value: latest
#Nh·∫≠p tham s·ªë cho job: CLUSTER_NAME (Choice), Cho ch·ªçn 2 gi√° tr·ªã l√†: udemy-devops-cluster-blue, udemy-devops-cluster-green
#S·ª≠ d·ª•ng code Pipeline trong file: blue-green_job2-deploy-ecs.groovy
# S·ª≠a ECR repository url c·ªßa b·∫°n.
#Save job l·∫°i.

#Ch·∫°y th·ª≠ v√† ki·ªÉm tra job deploy.
#Ch·ªânh s·ª≠a code html c·ªßa trang index, th√™m ƒëo·∫°n text "v1.0.1".

```
git add .
git commit -m "Update version 1.0.1"
git push origin master
#T·∫°o m·ªôt tag v√† push l√™n github repository c·ªßa b·∫°n. Vd: v1.0.1
git tag -a v1.0.1 -m "Release v1.0.1"
git push origin v1.0.1

```

#Ch·∫°y job [BlueGreen-Job1-Build] v·ªõi tham s·ªë version = v1.0.1
#Ki·ªÉm tra job ch·∫°y th√†nh c√¥ng v√† image ƒë√£ ƒë∆∞·ª£c push l√™n ECR repository.

#Ch·∫°y job [BlueGreen-Job2-Deploy-ECS] v·ªõi tham s·ªë version = v1.0.1, cluster_name = udemy-devops-cluster-green
#Truy c·∫≠p ALB v√† ki·ªÉm tra trang index hi·ªÉn th·ªã ƒë√∫ng version tr√™n c·∫£ 2 listener c·ªßa ALB.
#<ALB DNS>:/80 =>k·∫øt qu·∫£ ra version 1.0.0
#<ALB DNS>:/81 =>k·∫øt qu·∫£ ra version 1.0.1


#==========Step 5: T·∫°o Job Switch traffic:
#Add Policy cho IAM Role c·ªßa Jenkins ƒë·ªÉ c√≥ quy·ªÅn switch traffic gi·ªØa 2 Target Group.
#Policy name: ElasticLoadBalancingFullAccess

#T·∫°o m·ªôt Job Jenkins m·ªõi, ƒë·∫∑t t√™n l√† BlueGreen-Job3-Switch-Traffic.
#S·ª≠ d·ª•ng code Pipeline trong file: blue-green_job3-switch-traffic.groovy
#  - S·ª≠a th√¥ng tin ALB_ARN th√†nh ARN c·ªßa ALB c·ªßa b·∫°n.
#Save job l·∫°i.

#Ch·∫°y job [BlueGreen-Job3-Switch-Traffic] v√† ki·ªÉm tra trang index hi·ªÉn th·ªã ƒë√∫ng version tr√™n c·∫£ 2 listener c·ªßa ALB.
#<ALB DNS>:/80 =>k·∫øt qu·∫£ ra version 1.0.1
#<ALB DNS>:/81 =>k·∫øt qu·∫£ ra version 1.0.0


#==========Step 6: T·∫°o Job Clear resource:
#T·∫°o m·ªôt Job Jenkins m·ªõi, ƒë·∫∑t t√™n l√† BlueGreen-Job4-Clear-Resource.
#Nh·∫≠p tham s·ªë cho job: CLUSTER_NAME (Choice), Cho ch·ªçn 2 gi√° tr·ªã l√†: udemy-devops-cluster-blue, udemy-devops-cluster-green
#S·ª≠ d·ª•ng code Pipeline trong file: blue-green_job4-clear-resource.groovy
#Save job l·∫°i.

#ki·ªÉm tra xem code tr√™n cluster blue hay green ƒëang c≈© h∆°n?
#Ch·∫°y job [BlueGreen-Job4-Clear-Resource] v·ªõi tham s·ªë cluster_name = <cluster name x√°c nh·∫≠n ·ªü b∆∞·ªõc tr√™n>
#Ki·ªÉm tra tr√™n AWS console xem task ƒë√£ b·ªã stop h·∫øt ch∆∞a?





### üåê Full Flow Overview:


```
User (Internet)
    ‚Üì
CloudFront CDN (HTTPS, custom domain + caching)
    ‚Üì
S3 Static Website (Frontend React / FE assets)
    ‚Üì
Application Requests
    ‚Üì
ALB (HTTP/HTTPS ‚Äì public, gateway API routing)
    ‚Üì
ECS Service (Backend API in private subnet)
    ‚Üì
RDS (private DB subnet, port 3306)

```



### üîê Security Group Rules Overview

#### üìå Public NLB Security Group (Public SG)

| **Direction** | **Type** | **Port** | **Source/Destination** | **Purpose**                                      |
|---------------|----------|----------|-------------------------|--------------------------------------------------|
| Inbound       | HTTP     | 80       | 0.0.0.0/0               | Allow traffic from the internet                  |
| Outbound      | HTTP     | 80       | NGINX SG                | Forward request to NGINX reverse proxy           |

---


#### üìå Private NLB Security Group

| **Direction** | **Type** | **Port** | **Source/Destination** | **Purpose**                                      |
|---------------|----------|----------|-------------------------|--------------------------------------------------|
| Inbound       | HTTP     | 8080     | NGINX SG                | Accept traffic from NGINX                        |
| Outbound      | HTTP     | 8080     | ECS Task SG             | Forward to ECS application container             |

---

#### üìå ECS Task Security Group

| **Direction** | **Type** | **Port** | **Source/Destination** | **Purpose**                                      |
|---------------|----------|----------|-------------------------|--------------------------------------------------|
| Inbound       | HTTP     | 8080     | Private NLB SG          | Accept traffic from Private NLB                  |
| Outbound      | All      | All      | 0.0.0.0/0               | Allow internet and DB access                     |

---

#### üìå Private DB Security Group

| **Direction** | **Type**    | **Port** | **Source/Destination** | **Purpose**                                      |
|---------------|-------------|----------|-------------------------|--------------------------------------------------|
| Inbound       | MySQL/Aurora| 3306     | ECS Task SG             | Accept DB queries from ECS task                  |
| Outbound      | All         | All      | 0.0.0.0/0               | Allow system updates, DNS, etc.                  |




## III. High-Level Goals for 99.95% SLA

### Availability & Resilience Strategy

| **Area**              | **Objective**                                                       |
|-----------------------|---------------------------------------------------------------------|
| **High Availability** | Avoid single points of failure (use Multi-AZ & AutoFailover)       |
| **Data Durability**   | Enable automated backups and cross-region replication              |
| **Minimal Downtime**  | Use safe deployment strategies (`create_before_destroy`)           |
| **Disaster Recovery** | Define and test DR runbooks (manual + automated recovery)          |
| **Monitoring & Alerts** | Detect failures fast with alarms and metrics                     |


### Multi-AZ RDS for High Availability

#### ‚òëÔ∏è Terraform Task

- Use multi_az = true in your RDS configuration.
- Choose instance class that supports Multi-AZ (e.g., db.m6g.large or above).

```
resource "aws_db_instance" "primary" {
  identifier         = "app-prod-db"
  engine             = "mysql"
  instance_class     = "db.m6g.large"
  multi_az           = true
  ...
}
```

#### ‚òëÔ∏è Outcome

- Failover to standby in the other AZ within 1‚Äì2 minutes.
- AWS manages data replication between AZs.


### Cross-Region Backups

#### ‚òëÔ∏è Terraform Task

- Enable `backup_retention_period` and `copy_tags_to_snapshot`
- Use `aws_db_snapshot` and `aws_db_snapshot_copy` for cross-region copies.

```
resource "aws_db_snapshot_copy" "cross_region" {
  source_db_snapshot_identifier = aws_db_snapshot.primary_snapshot.id
  target_db_snapshot_identifier = "db-copy-${timestamp()}"
  kms_key_id                    = aws_kms_key.replica.arn
  source_region                 = var.primary_region
}
```

#### ‚òëÔ∏è Outcome
- Backups stored securely in another region for DR readiness.

### Safe Deployments with create_before_destroy

#### ‚òëÔ∏è Terraform Task

- Use lifecycle blocks on resources like:
  - Security groups
  - IAM roles
  - Subnets / route tables
  - NLBs
  - EC2 instances

```
resource "aws_security_group" "db_sg" {
  name = "db-sg"

  lifecycle {
    create_before_destroy = true
  }
}

```

#### ‚òëÔ∏è Outcome

- Avoids downtime when updating critical infra like SGs or route tables.

### Disaster Recovery (DR) Playbook

#### ‚òëÔ∏è Manual or Automated Steps

- Document procedures to restore from cross-region snapshot:
  - Launch RDS from snapshot
  - Update DNS or failover route in Route 53
- Terraform module to quickly stand up infrastructure in secondary region

#### ‚òëÔ∏è Automation Tip:
- Use `terraform workspace` or terragrunt to replicate infra to secondary region.


### Monitoring, Alarms, and Failover Automation

- Use CloudWatch Alarms:
  - RDS status checks
  - Freeable memory, CPU, storage thresholds

```
resource "aws_cloudwatch_metric_alarm" "aurora_cpu_high" {
  count               = var.db_mode == "aurora" ? 1 : 0
  alarm_name          = "aurora-cpu-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 3
  metric_name         = "CPUUtilization"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 80
  alarm_description   = "Alarm when Aurora CPU exceeds 80%"
  dimensions = {
    DBClusterIdentifier = aws_rds_cluster.aurora[0].id
  }
  alarm_actions       = [var.sns_topic_arn]  # Send notifications
}

resource "aws_cloudwatch_metric_alarm" "aurora_replica_lag" {
  count               = var.db_mode == "aurora" ? 1 : 0
  alarm_name          = "aurora-replica-lag-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 3
  metric_name         = "AuroraReplicaLag"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 60 # seconds
  alarm_description   = "Alarm when Aurora Replica lag exceeds 60 seconds"
  dimensions = {
    DBClusterIdentifier = aws_rds_cluster.aurora[0].id
  }
  alarm_actions       = [var.sns_topic_arn]
}


```

- CloudWatch Metrics for RDS/Aurora

AWS RDS/Aurora automatically sends key performance and health metrics to CloudWatch, including:

| Metric               | Description                      | Why monitor it?                   |
|----------------------|---------------------------------|---------------------------------|
| CPUUtilization       | % of CPU used                   | Detect high load / bottlenecks  |
| FreeableMemory       | Available RAM (bytes)           | Prevent out-of-memory errors    |
| DatabaseConnections  | Number of active DB connections | Avoid connection saturation     |
| FreeStorageSpace     | Free disk space available       | Avoid running out of disk       |
| ReadIOPS / WriteIOPS | I/O operations per second       | Check for unusual or high I/O load |
| ReadLatency / WriteLatency | Time taken for read/write operations | Detect slow queries or storage issues |
| ReplicaLag           | Lag time of replicas (Aurora only) | Ensure replicas are up-to-date |
| DiskQueueDepth       | Number of pending IO requests   | Identify storage bottlenecks    |
| SwapUsage            | Swap space used                 | Can indicate memory pressure    |


- In a real project, how would you apply CloudWatch for RDS/Aurora?
  - Baseline Metrics & Thresholds: Understand your workload baseline (normal CPU, memory, IOPS). Set thresholds slightly above baseline.

  - Create Alarms for Key Metrics: CPU, storage space, connections, replica lag, latency.

  - Setup Notifications: Use SNS to send alerts to DevOps team via email, Slack, PagerDuty.

  - Automated Actions (optional): Use CloudWatch Event Rules + Lambda to automate scale up/down, or perform remediation.

  - Dashboards: Create CloudWatch Dashboards to visualize trends and performance in one place.

  - Logs: Enable enhanced monitoring & export RDS logs (slow query logs, error logs) to CloudWatch Logs for deeper insights.

  - Integrate with CI/CD: Use alarms as gates to halt deployments if DB performance is degraded.



## IV. Module Documentation

### 1. CI/CD Pipeline (GitHub Actions)

üîπ Overview

This pipeline automates build, code scanning, artifact management, image building, security scanning, and deployment to ECS and Nginx.

üî∏ Workflow Steps:

Backend (Java):

- Checkout source code from GitHub
- Run SonarCloud scan
- Build with Maven
- Push artifacts to JFrog Artifactory
- Build Docker image
- Scan image with Trivy
- Push to AWS ECR
- Deploy image to ECS

Frontend (Static):

- Checkout frontend code
- Build static files (React/Angular/etc.)
- Copy build output to Nginx EC2 server via SSH or deploy with S3 + CloudFront

#### üìÅ GitHub Actions Folder Structure:

```
.github/
  workflows/
    aj3-terraform-ci.yml
    aj3-build-cicd.yml

```

#### Documentation for CICD

[üìò How to setup terraform with Ansible ](https://devopsvn.tech/terraform-series/terraform/bai-13-ansible-with-terraform)

[üìò Dependencies Installation ](docs/AJ3-prequisite-setup.md)

[üìò Github Action CICD Terraform Infra](docs/AJ3-CICD-Infra.md)

[üìò Github Action CICD for Build Docker Image](docs/AJ3-CICD-build.md)


### 2. Terraform Infrastructure Modules

üîπ Overview

All infrastructure is provisioned as modular Terraform code.

üî∏ Modules Breakdown

#### üì¶ Terraform Module Overview

| Module         | Purpose                                                         |
|----------------|-----------------------------------------------------------------|
| `network`          | Create VPC, public/private subnets, IGW, NAT, and route tables, Transit Gateway  |
| `security`     | Define and attach Security Groups  |
| `bastion`      | Launch EC2 instance in public subnet for SSH access |
| `nginx`        | Deploy EC2 instance for static frontend (Nginx server), install sonarqube server          |
| `database`     | Provision RDS (MySQL) with Multi-AZ, Amazon MQ (e.g., ActiveMQ), Memcached via ElastiCache |
| `autoscaling`  | Set up Auto Scaling Group for application servers               |
| `nlb`          | Configure public/private Network Load Balancers                 |
| `iam`          | Create IAM roles and policies for EC2, ECS, and other services  |
| `ecs`          | Create ECS cluster |



#### üìÅ Recommended Structure:

```
terraform/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îî‚îÄ‚îÄ network/
‚îÇ       ‚îî‚îÄ‚îÄ main.tf        
‚îÇ   ‚îî‚îÄ‚îÄ bastion/
‚îÇ       ‚îî‚îÄ‚îÄ main.tf        
‚îÇ   ‚îî‚îÄ‚îÄ ecs/
‚îÇ       ‚îî‚îÄ‚îÄ main.tf        
‚îÇ   ‚îî‚îÄ‚îÄ security/
‚îÇ       ‚îî‚îÄ‚îÄ main.tf        
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ       ‚îî‚îÄ‚îÄ main.tf        
‚îú‚îÄ‚îÄ envs/
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îú‚îÄ‚îÄ uat/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îî‚îÄ‚îÄ pre-prod/
‚îÇ       ‚îú‚îÄ‚îÄ backend.tf
‚îÇ       ‚îî‚îÄ‚îÄ terraform.tfvars
‚îî‚îÄ‚îÄ variables.tf           # Common variable definitions

```
#### Terraform design module

![alt text](aj3-terraform-module-design.drawio.png)


#### Create Separate Environments with Workspaces

To use workspaces, eg. DEV environment

```
terraform workspace new dev
terraform workspace select dev
terraform apply -var-file="envs/dev/terraform.tfvars"

```

#### Use Environment-specific Variables

```
env_name       = "dev"
vnet_name      = "dev-vnet"
address_space  = "10.0.0.0/16"
location       = "East US"
resource_group = "rg-dev"

```

#### Use Separate Backends

For state separation across environments, define different backends.

Eg. `envs/dev/backend.tf`

```
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket"   
    key            = "dev/terraform.tfstate"        
    region         = "us-east-1"                    
    dynamodb_table = "terraform-locks"              
    encrypt        = true                           
  }
}

```


### 3. Golden AMI Creation

üîπ Overview

Custom AMIs are created to speed up instance launch and enforce consistency.

üî∏ Global Base AMI

Install: AWS CLI, CloudWatch Agent, SSM Agent

üî∏ Specialized AMIs:

- Nginx AMI: Install nginx, configure memory metrics
- Tomcat AMI: Install Tomcat, Java 11, systemd setup
- Maven Build AMI: Install Maven, Git, Java 11, preconfigure environment

üìå Optionally use Packer for automation.

### 4. Monitoring & Logging

#### üîç Monitoring & Logging

| Tool           | Purpose                                                                 |
|----------------|-------------------------------------------------------------------------|
| `CloudWatch`   | Log and metric collection for EC2, RDS, and application components       |
| `Cronjob + S3` | Push Tomcat logs to S3 and rotate local logs to save disk space         |
| `Alarms`       | Trigger email alerts on threshold breaches (e.g., DB connections > 100) |
| `SNS`          | Send notifications via Email/SMS when alarms are triggered              |


### 5. Application Lifecycle

#### üîÑ Application Lifecycle

| Phase                   | Tasks                                                                 |
|-------------------------|-----------------------------------------------------------------------|
| `Pre-Deployment`        | Build custom AMIs, configure monitoring agents, SonarCloud & JFrog setup |
| `Infrastructure Deployment` | Run Terraform pipelines to provision AWS infrastructure               |
| `CI/CD Execution`       | Build, scan, and deploy applications using GitHub Actions workflows   |
| `Post-Deployment`       | Set up CloudWatch alerts, validate deployment, and configure log rotation |


## VI. Security Best Practices

- Store secrets in GitHub Secrets or AWS Parameter Store
- Use IAM roles, avoid access keys in pipelines
- Principle of Least Privilege (SGs, IAM, S3 access)
- S3 VPC Endpoint instead of public access
- Enable logging: CloudTrail, VPC Flow Logs

